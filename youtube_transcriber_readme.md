# YouTube Transcriber avec Whisper

Un programme Python avec interface graphique pour transcrire automatiquement des vidÃ©os YouTube en utilisant OpenAI Whisper. OptimisÃ© pour GPU NVIDIA (RTX 3090).

## ğŸš€ FonctionnalitÃ©s

- **Interface graphique intuitive** avec Tkinter
- **Transcription haute qualitÃ©** avec Whisper large-v3
- **Support GPU CUDA** pour une transcription rapide
- **Traitement en batch** de plusieurs vidÃ©os
- **DÃ©tection automatique de la langue** (franÃ§ais/anglais)
- **Logs dÃ©taillÃ©s** avec barre de progression
- **Nettoyage automatique** des fichiers temporaires
- **Timestamps inclus** dans les transcriptions

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- FFmpeg installÃ© sur le systÃ¨me
- GPU NVIDIA avec CUDA (recommandÃ©) ou CPU
- 8GB+ de RAM (16GB+ recommandÃ© pour le modÃ¨le large)
- ~10GB d'espace disque pour le modÃ¨le Whisper large-v3

## ğŸ”§ Installation

### 1. Cloner ou tÃ©lÃ©charger les fichiers

CrÃ©ez un nouveau dossier et placez-y les fichiers :
- `main.py`
- `transcriber.py`
- `requirements.txt`

### 2. Installer FFmpeg

**Windows:**
1. TÃ©lÃ©charger depuis [ffmpeg.org](https://ffmpeg.org/download.html)
2. Extraire et ajouter le dossier `bin` au PATH systÃ¨me

**Linux (Ubuntu/Debian):**
```bash
sudo apt update
sudo apt install ffmpeg
```

**macOS:**
```bash
brew install ffmpeg
```

### 3. CrÃ©er un environnement virtuel (recommandÃ©)

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 4. Installer PyTorch avec CUDA (pour RTX 3090)

```bash
# Pour CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Pour CUDA 12.1 (plus rÃ©cent)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 5. Installer les autres dÃ©pendances

```bash
pip install openai-whisper yt-dlp ffmpeg-python
```

### 6. Premier lancement (tÃ©lÃ©chargement du modÃ¨le)

Le premier lancement tÃ©lÃ©chargera automatiquement le modÃ¨le Whisper large-v3 (~3GB). Cela ne se fera qu'une seule fois.

## ğŸ’» Utilisation

### Lancer le programme

```bash
python main.py
```

### Interface graphique

1. **Coller les URLs** : Entrez une ou plusieurs URLs YouTube (une par ligne)
2. **Lancer la transcription** : Cliquez sur "ğŸ¬ Lancer la transcription"
3. **Suivre la progression** : 
   - Barre globale : nombre de vidÃ©os traitÃ©es
   - Barre dÃ©taillÃ©e : Ã©tape actuelle (tÃ©lÃ©chargement/transcription)
   - Logs : informations dÃ©taillÃ©es en temps rÃ©el
4. **RÃ©sultats** : Les transcriptions sont sauvegardÃ©es dans le dossier `transcriptions/`

### Format de sortie

Les fichiers de transcription incluent :
- Titre de la vidÃ©o
- Date et heure de transcription  
- Langue dÃ©tectÃ©e
- Texte complet
- Version avec timestamps (minutes:secondes)

## âš¡ Optimisation des performances

### Avec RTX 3090 (configuration actuelle)

- **ModÃ¨le large-v3** : ~2-3x plus rapide que le temps rÃ©el
- Une vidÃ©o de 10 minutes est transcrite en 3-4 minutes
- Utilisation de FP16 pour accÃ©lÃ©rer les calculs

### Choix du modÃ¨le selon votre matÃ©riel

| ModÃ¨le | VRAM nÃ©cessaire | QualitÃ© | Vitesse (RTX 3090) |
|--------|----------------|---------|---------------------|
| tiny | ~1 GB | â­â­ | ~10x temps rÃ©el |
| base | ~1 GB | â­â­â­ | ~7x temps rÃ©el |
| small | ~2 GB | â­â­â­â­ | ~5x temps rÃ©el |
| medium | ~5 GB | â­â­â­â­ | ~3x temps rÃ©el |
| large-v3 | ~10 GB | â­â­â­â­â­ | ~2-3x temps rÃ©el |

Pour changer le modÃ¨le, modifiez la ligne dans `main.py` :
```python
self.transcriber = YouTubeTranscriber(
    output_dir=self.output_dir,
    model_size='large-v3',  # Changer ici
    device='cuda',
    message_queue=self.message_queue
)
```

## ğŸ› RÃ©solution des problÃ¨mes

### "CUDA non disponible"

VÃ©rifiez votre installation CUDA :
```python
python -c "import torch; print(torch.cuda.is_available())"
```

Si False, rÃ©installez PyTorch avec la bonne version CUDA.

### "ffmpeg not found"

Assurez-vous que FFmpeg est dans le PATH systÃ¨me :
```bash
ffmpeg -version
```

### Erreur de mÃ©moire GPU

Si vous manquez de VRAM, utilisez un modÃ¨le plus petit ou passez sur CPU :
```python
device='cpu'  # Dans main.py
```

### VidÃ©o privÃ©e ou gÃ©o-bloquÃ©e

Le programme continuera avec les autres vidÃ©os et indiquera l'erreur dans les logs.

## ğŸ“ Structure des fichiers

```
youtube-transcriber/
â”œâ”€â”€ main.py              # Interface graphique
â”œâ”€â”€ transcriber.py       # Logique de transcription
â”œâ”€â”€ requirements.txt     # DÃ©pendances
â”œâ”€â”€ README.md           # Documentation
â””â”€â”€ transcriptions/     # Dossier de sortie (crÃ©Ã© automatiquement)
    â”œâ”€â”€ video1_20240115_143022.txt
    â”œâ”€â”€ video2_20240115_143512.txt
    â””â”€â”€ ...
```

## ğŸ”’ ConsidÃ©rations lÃ©gales

- Respectez les droits d'auteur des vidÃ©os
- Utilisez uniquement pour un usage personnel ou avec permission
- VÃ©rifiez les conditions d'utilisation de YouTube

## ğŸ“Š Exemples de cas d'usage

- CrÃ©er des notes de cours Ã  partir de vidÃ©os Ã©ducatives
- Archiver des podcasts ou interviews
- GÃ©nÃ©rer des sous-titres pour vos propres vidÃ©os
- Analyser le contenu de vidÃ©os pour la recherche
- CrÃ©er des rÃ©sumÃ©s de confÃ©rences

## ğŸš€ AmÃ©liorations futures possibles

- [ ] Support de plus de langues
- [ ] Export en formats SRT/VTT pour sous-titres
- [ ] RÃ©sumÃ© automatique avec LLM
- [ ] Traduction automatique
- [ ] Support des playlists YouTube
- [ ] Mode CLI pour automatisation
- [ ] API REST pour intÃ©gration

## ğŸ“ Notes

- La premiÃ¨re transcription sera plus lente car le modÃ¨le doit Ãªtre chargÃ© en mÃ©moire
- Les vidÃ©os trÃ¨s longues (>1h) peuvent prendre du temps
- La qualitÃ© de transcription dÃ©pend de la qualitÃ© audio de la vidÃ©o source

## ğŸ¤ Support

Pour toute question ou problÃ¨me, vÃ©rifiez d'abord que :
1. FFmpeg est correctement installÃ©
2. Vous avez assez d'espace disque
3. Votre GPU est reconnu (si utilisation CUDA)
4. Les URLs YouTube sont valides et publiques

Bon transcribing! ğŸ‰